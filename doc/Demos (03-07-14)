Demos for Friday, March 7th:
Author: Jacob Reske
Advisors: Ian Quin, Brian Kane


1. Million Song Dataset
	- Flatfile representation of MSD uploaded to S3 (major hurdle)
	- Using track.py and track_getter, can list dataset as array, split into separate .dat files, easy to view, manipulate, etc.
	- Track headers are stored in track.py, easier to read in data/trackheaders
	- Script
		python msd_parser.py tiny.dat [args]
		(list songname in input, in this case tiny.dat, + MSD values. Good debugger)

2. Preview download using 7Digital API:
	- downloads 30-second previews of tracks in MSD 
	- if song_ID isn't present, searches 7digital for song name/artist name until it finds a match
	- will be baked into mapreduce job to analyze individual songs (easy to do with MRjob)
	- script (downloads 20 songs to localdir present in tiny.dat, also splits into training and test set):
		python track_getter.py tiny.dat

3. AWS integration - density test
	- uploads script + tarball to emr nodes
	- uses s3 bucket of flatfile MSD --> MUCH easier to work with
	- executes simple mapreduce job to find density
	- Density: "Average number of notes or atomic sounds (segments) per second in a song"
		- Essentially transient detector, more lenient, to detect 'segments' in a song.
		- density is # of segments / second
		- could be used to model genre, decade published, etc.
	- source: http://musicmachinery.com/2011/09/04/how-to-process-a-million-songs-in-20-minutes/
	- script:
		python density.py --num-ec2-instances 10 --python-archive t.tar.gz -r emr 's3://tbmmsd/*.tsv.*' > out.dat
	- output will be in out.dat (top most dense songs). I accidentally overwrote it, next time I run it it will have current info
	- expensive (relative to the number of nodes you have running). 10 node setup for 2 hour job (above) costs ~$5.

4. Remix 
	- From the EchoNest API
	- Probably won't use, more for DSP/sound manipulation
	- Still pretty cool. Could use beat detector for tempo as regression on year/genre, other multi-dimensional nodes
	- Demo: beat detector, reverses order of tracks
	- Script (in /analyze):
		python REMIXanalyzer (for one demo)
		python mp3edit.py (for multiple files)

5. Audio Analysis
	- Biggest technical hurdle so far.
	- My immediate plan: extract MFCCs (mel-frequency cepstrum coefficients). Highly cited in genre classification. Use MFCC array as a baseline for ML algorithms in addition to supervised data from the Million Song Dataset.
	- Candidates:
		- Aubio (http://aubio.org/). Advantages: onset detection, PITCH TRACKING, MFCCs, transient detection, you name it, math utilities built in. Disadvantages: not python native (C), hasn't been cooperating.
		- Yaafe. Advantages: Very detailed, good documentation. Disadvantages: dependencies being awful, problems with current machine + gcc??
		- LibROSA. Advantages: easy to use, well-documented, mp3 support, python native. Disadvantages: IMPOSSIBLE to solve bug currently with OSX 10.9

6. Machine Learning algos
	- scikit-learn (http://scikit-learn.org/stable/)
	- very robust, many algorithms, detailed documentation
	- want to get analysis running before I do big ML jobs, but suffice to say it's very easy to run jobs, also to integrate with MRJob
	- Biggest work will be re-writing in terms of map/reduce jobs. Luckily I'm using 2 algorithms at most, regression + classification

7. What's next
	- Supervised
		- Determining genre based on continuous data (tempo, hotness, density other MSD things)
		- Determining year based on genre, tempo, density
	- Unsupervised
		- breakup of songs into MFCC segments, pattern-matching and error-checking. Also beat detection segments. Clustering algorithm, small # of classes (~20 to start) but large # of splits
	- Code to do: 
		- get MFCC analysis to work, not too hard
		- get ML algorithms up and running
		- interface with MRJob
	- Ultimate goal:
		- determing genre in parallel: MFCCs alone, MFCCs and beat detection, etc. 
		- Or with MFCCs and supervised dataset. 
		- Presto, we have results!
